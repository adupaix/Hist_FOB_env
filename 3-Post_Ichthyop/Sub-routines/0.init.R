#'#*******************************************************************************************************************
#'@author : Amael DUPAIX
#'@update : 2021-02-24
#'@email : 
#'#*******************************************************************************************************************
#'@description :  Initialize the analysis (functions, paths, file names, log file)
#'#*******************************************************************************************************************
#'@revision
#'#*******************************************************************************************************************


# Load functions used in the following sub-routines:

# source(file.path(FUNC_PATH, "1.nc.to.Array.R"))
# source(file.path(FUNC_PATH, "1.read.river.data.R"))
source(file.path(FUNC_PATH, "1.subfunctions.R"))
source(file.path(FUNC_PATH,'2.subfunctions.R'))

# Create the name of the simulation from the arguments
sim_name <- generate.sim_name(forcing,
                                input_location,
                                input_method,
                                dist,
                                dispersion,
                                bouncing)
  
# Create output folder
output_path_1 <- file.path(OUTPUT_PATH, sim_name, year, "1.nb_cover")
output_path_2 <- file.path(OUTPUT_PATH, sim_name, year, paste0("2.points_info_w",weight_method,
                                                         ifelse(is.null(thr_disch), "_no-thr-disch", paste0("_thr-disch",thr_disch))))
dir.create(output_path_1, recursive = T, showWarnings = F)
dir.create(output_path_2, recursive = T, showWarnings = F)

# If RESET is T, delete all the output files
if (RESET == T){
  try(file.remove(c(list.files(output_path_1, full.names = T),
                    list.files(output_path_2, full.names = T)),
                  recursive = T),
      silent = T)
}

cat("\14")

#'@read_rivers
#'**********
cat(bold("0. Initializing:\n\n"))
cat("Reading and filtering rivers file\n")
cat("    - Reading\n")

rivers_IO <- readRDS(file.path(DATA_PATH, "river_data", "rivers_IO.rds"))

cat("    - Filtering\n")

#' filter rivers
rivers_IO %>%
  # garde uniquement les embouchures
  # (identifiant de la portion de riviere = a l'identifiant principal de la riviere)
  dplyr::filter(HYRIV_ID == MAIN_RIV) %>%
  # garde uniquement les portions de riviere qui se jettent dans la mer
  dplyr::filter(ENDORHEIC == 0) %>%
  # garde uniquement les fleuves avec un debit maximal de plus d 100 m3 par seconde
  dplyr::filter(dis_m3_pmx >= thr_disch) -> embouchures

# keep only variables of interest
rivers_IO %>%
  dplyr::filter(MAIN_RIV %in% embouchures$HYRIV_ID) %>%
  dplyr::filter(dis_m3_pmx >= thr_disch) %>%
  dplyr::select(HYRIV_ID, #id de la portion de riviere
                NEXT_DOWN,#id de la portion en aval
                MAIN_RIV, # id de la portion qui se jette dans la mer
                LENGTH_KM, # longueur de la portion en km
                HYBAS_L12, # id du bassin versant,
                #pour faire le lien avec l'autre base de donnees
                dis_m3_pyr, # debit moyen en m3/s
                dis_m3_pmn, # debit minimal en m3/s
                dis_m3_pmx # debit maximal
  ) -> rivers_filtered

#' Create output files names
nCoverPoints <- file.path(output_path_1, "number_of_cover_points_per_input_point.csv")
#' 
# logName <- file.path(NEW_OUTPUT_PATH, paste0("Per_",agg.time_scale,"_0.log.txt"))
# globalName <- file.path(NEW_OUTPUT_PATH, "1.global_array.rds")
# meanAggName <- file.path(NEW_OUTPUT_PATH, paste0("Per_",agg.time_scale,"_2.mean_aggregated_array.rds"))
# aggregateName <- file.path(NEW_OUTPUT_PATH, paste0("Per_",agg.time_scale,"_3.aggregated_array.rds"))
# plotListName <- file.path(NEW_OUTPUT_PATH, paste0("Per_",agg.time_scale,"_3.maps.rds"))
# meanPlotListName <- file.path(NEW_OUTPUT_PATH, paste0("Per_",agg.time_scale,"_2.mean_maps.rds"))
# mapName <- file.path(NEW_OUTPUT_PATH, paste0("Per_",agg.time_scale,"_maps.png"))

# Logical to know if files exist
nCoverExists <- file.exists(nCoverPoints)

# For parallel study:
# On Windows, or if don't want to parralelize, set cores number to 1
if (.Platform$OS.type == "windows" | as.logical(Parallel[1]) == F) {
  nb_cores = 1
} else { #use a fraction of the available cores
  nb_cores = trunc(detectCores() * as.numeric(Parallel[2]))
}

# # Do not delete
# DoNotDeleteMe <- c("DoNotDeleteMe", ls())
# 
# # Delete the output files already created if RESET = T
# if (any(RESET) & any(filesExist)){
#   
#   # if RESET[1] = T, delete the files which exist generated by the two sub_routines 
#   if(RESET[1]){
#     invisible(file.remove(c(logName, globalName, meanAggName, aggregateName,
#                             plotListName, meanPlotListName, mapName)[filesExist] ))
#   }
#   # if RESET[2] = T, delete the files generated by the second sub_routine which exist
#   if (RESET[2]){
#     invisible(file.remove(c(plotListName, meanPlotListName, mapName)[filesExist[5:7]]))
#   }
# }
# 
# # Logical to know if files exist (to know if they need to be calculated)
# glob_array_exists <- file.exists(globalName)
# mean_agg_array_exists <- file.exists(meanAggName)
# agg_array_exists <- file.exists(aggregateName)
# 
# # Create log file
# sink(logName, append = T)
#   
# cat("#### FROM SIMUALTION RESULTS TO MAPS ####\n=========================================\n Date & Time:",format(Sys.time()),"\n\n")
# cat("1. GENERATING ARRAY FROM SIMULATION RESULTS")
# cat("\n Execution time :", format(Sys.time()))
# cat("\n\n### SIMULATION CHARACTERISTICS")
# cat(paste("\n Forcing product :", forcing))
# cat(paste("\n Location of input points :", input_location))
# cat(paste("\n Method for input points :", input_method))
# 
# if (input_method == "kFromCoast"){
#   cat(paste0("\n Distance of input from coast : ", dist, "km"))
# }
# cat(paste0("\n Dispersion coefficient : 10^-", dispersion, " m^2/s^3"))
# cat(paste0("\n Bouncing on coast : ", bouncing, "\n\n"))
# 
# cat("### ARGUMENTS USED")
# cat(paste("\n Life time :", ltime, "days"))
# cat(paste("\n Life time method :", ltime_method))
# cat(paste("\n Weighting method :", weight_method))
# cat(paste("\n Grid cell size :", gsize, "degrees"))
# cat(paste("\n Aggregating time scale :", agg.time_scale))
# cat(paste("\n Discharge threshold :", ifelse(is.null(thr_disch), "NULL", paste(thr_disch, "m3/s"))))
# cat(paste("\n Using parallelization :", as.logical(Parallel[1])))
# cat(paste("\n Number of cores used :", ifelse(Parallel[1]==F, 1, trunc(detectCores() * Parallel[2]))))
# 
# sink()
